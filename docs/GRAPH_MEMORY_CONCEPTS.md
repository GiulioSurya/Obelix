# Graph-Based Memory System per Obelix

> **Status**: Concept Development
> **Ispirazione**: Parlant Relationships & Journey Graphs
> **Obiettivo**: Memoria condivisa tra sub-agent senza stato globale monolitico

---

## ğŸ¯ Problema da Risolvere

### Situazione Attuale
In Obelix, quando un **orchestrator** coordina multipli **sub-agent**, ogni sub-agent opera in isolamento:

```
Orchestrator
    â”œâ”€> SubAgent A (analyzer)    â†’ conversation_history_A
    â”œâ”€> SubAgent B (validator)   â†’ conversation_history_B
    â””â”€> SubAgent C (reporter)    â†’ conversation_history_C
```

**Problemi:**
1. **Ridondanza**: Se B deve validare il lavoro di A, l'orchestrator deve ri-inserire tutto il contesto di A nella query per B
2. **Perdita di contesto**: Le connessioni semantiche tra output di diversi agent sono implicite (solo nell'orchestrator)
3. **ScalabilitÃ **: Con N sub-agent, la complessitÃ  di coordinazione cresce quadraticamente
4. **Mancanza di tracciabilitÃ **: Non c'Ã¨ modo di ricostruire "perchÃ© B ha prodotto X dato che A ha prodotto Y"

### Soluzione Alternativa 1: Stato Globale Condiviso
```python
# âŒ Approccio naive
shared_state = {
    "analyzer_result": {...},
    "validator_result": {...},
    "reporter_result": {...}
}
```

**Svantaggi:**
- Accoppiamento forte tra agent (devono conoscere le chiavi)
- Nessuna semantica sulle relazioni (tutto Ã¨ "flat")
- Difficile gestire invalidazioni (se A ri-esegue, B deve saperlo?)
- Race conditions in esecuzione parallela

---

## ğŸ’¡ Idea Core: Memoria come Grafo

### Visione
Invece di uno stato condiviso monolitico, ogni **output significativo** di un agent diventa un **nodo** in un grafo di memoria. Le **relazioni semantiche** tra output diventano **archi** nel grafo.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MEMORY GRAPH                             â”‚
â”‚                                                             â”‚
â”‚   [User Input]                                              â”‚
â”‚        â”‚                                                    â”‚
â”‚        â”œâ”€DERIVES_FROMâ”€> [Raw Data]                         â”‚
â”‚        â”‚                     â”‚                              â”‚
â”‚        â”‚                     â”œâ”€DERIVES_FROMâ”€> [Analysis]    â”‚
â”‚        â”‚                     â”‚                     â”‚        â”‚
â”‚        â”‚                     â”‚                     â””â”€REQUIRESâ”€> [Validation] â”‚
â”‚        â”‚                     â”‚                                      â”‚        â”‚
â”‚        â””â”€SHARES_CONTEXTâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                              â”‚
â”‚                                    â””â”€DERIVES_FROMâ”€> [Final Report]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Vantaggi
1. **Memoria Selettiva**: Ogni agent accede solo alle memorie correlate (via BFS nel grafo)
2. **Semantica Esplicita**: Le relazioni (`DERIVES_FROM`, `REQUIRES`, ecc.) rendono esplicito il "perchÃ©"
3. **TracciabilitÃ **: Percorsi nel grafo = audit trail (chi ha prodotto cosa, basandosi su cosa)
4. **Invalidazione Automatica**: Se un nodo viene invalidato, posso marcare tutti i discendenti come "stale"
5. **Parallelismo**: Agent possono scrivere nodi concorrentemente (no lock su stato globale)

---

## ğŸ§© Componenti Concettuali

### 1. MemoryNode
**Cosa rappresenta**: Un'unitÃ  atomica di informazione prodotta da un agent

**ProprietÃ  chiave**:
- **Provenienza**: Chi l'ha creato? (agent_id)
- **Tipo**: Tool result, agent output, user input, observation
- **Contenuto**: Testo + dati strutturati (JSON)
- **Metadata**: Timestamp, tags, embedding_vector (per semantic search)

**Esempi**:
```
MemoryNode {
    id: "mem_abc123"
    agent_id: "analyzer_agent"
    type: AGENT_OUTPUT
    content: "Q4 sales increased 15% vs Q3..."
    structured_data: {revenue: 1.2M, growth: 0.15}
    timestamp: 2024-01-15T10:30:00Z
}
```

### 2. MemoryEdge (Relationship)
**Cosa rappresenta**: Una relazione semantica tra due memorie

**Tipi di relazioni** (ispirati da Parlant + estesi):

#### A. Relazioni di Derivazione
- **DERIVES_FROM**: `B` Ã¨ stato calcolato/inferito da `A`
  - Esempio: `[Analysis] DERIVES_FROM [Raw Data]`
  - Uso: Tracciare lineage dei dati

- **TRANSFORMS**: `B` Ã¨ una trasformazione di `A` (piÃ¹ specifico di DERIVES_FROM)
  - Esempio: `[Normalized Data] TRANSFORMS [Raw CSV]`
  - Uso: Pipeline di data processing

#### B. Relazioni di Dipendenza
- **REQUIRES**: `B` richiede `A` per essere comprensibile
  - Esempio: `[Validation Report] REQUIRES [Analysis]`
  - Uso: Quando validator legge analysis, crea REQUIRES

- **DEPENDS_ON**: `B` dipende funzionalmente da `A` (se A cambia, B deve ricalcolarsi)
  - Esempio: `[Forecast] DEPENDS_ON [Historical Data]`
  - Uso: Invalidazione automatica

#### C. Relazioni di Consistenza
- **INVALIDATES**: `B` rende `A` obsoleta
  - Esempio: `[Updated Analysis] INVALIDATES [Old Analysis]`
  - Uso: Gestire versioning delle memorie

- **CONTRADICTS**: `B` contraddice `A` (conflict detection)
  - Esempio: `[Validator Output] CONTRADICTS [Analyzer Output]`
  - Uso: Segnalare inconsistenze

- **CONFIRMS**: `B` conferma/valida `A`
  - Esempio: `[Validation Result] CONFIRMS [Analysis]`
  - Uso: Chain of trust

#### D. Relazioni di Contesto
- **SHARES_CONTEXT**: `A` e `B` condividono contesto (stessa query utente, stesso workflow)
  - Esempio: `[Analysis] SHARES_CONTEXT [Validation]` (entrambe sulla stessa query)
  - Uso: Raggruppamento logico

- **COMPLEMENTS**: `B` aggiunge informazioni a `A` senza invalidarla
  - Esempio: `[Risk Analysis] COMPLEMENTS [Financial Analysis]`
  - Uso: Prospettive multiple sullo stesso dato

#### E. Relazioni di Sequenza
- **FOLLOWS**: `B` segue temporalmente `A` (workflow step)
  - Esempio: `[Step 2: Validation] FOLLOWS [Step 1: Analysis]`
  - Uso: Ricostruire ordine di esecuzione

- **TRIGGERS**: `A` ha causato l'esecuzione che ha prodotto `B`
  - Esempio: `[Error Detection] TRIGGERS [Error Report]`
  - Uso: Causality tracking

### 3. MemoryGraph
**Cosa rappresenta**: Il grafo complessivo che connette tutte le memorie

**Operazioni chiave**:

#### Query Relazionali (BFS-based)
```
get_related_memories(node_id, relationship_kind, max_depth, direction)
â†’ Trova tutte le memorie correlate a distanza â‰¤ max_depth
```

**Esempi**:
- `get_related_memories("validation_123", REQUIRES, depth=2, direction="incoming")`
  â†’ Trova cosa Ã¨ stato richiesto per produrre la validazione (e cosa a sua volta era richiesto)

- `get_related_memories("analysis_456", DERIVES_FROM, depth=âˆ, direction="outgoing")`
  â†’ Trova tutta la chain di derivazioni dall'analisi

#### Context Building
```
get_context_for_agent(agent_id, max_memories)
â†’ Trova le memorie piÃ¹ rilevanti per un agent
```

**Strategia**:
1. Memorie create dall'agent (ownership)
2. Memorie con relazione REQUIRES/SHARES_CONTEXT (relevance)
3. Memorie recenti nello stesso workflow (temporal proximity)
4. Ordina per rilevanza (combination of factors)

#### Semantic Search (opzionale, richiede embeddings)
```
search_memories(query_text, agent_id?, top_k)
â†’ Vector search sugli embedding dei nodi
```

**Uso**: "Trova memorie simili a 'revenue analysis Q4'" anche senza conoscere gli ID

---

## ğŸ”„ Pattern di Utilizzo

### Pattern 1: Linear Pipeline
**Scenario**: Workflow sequenziale (A â†’ B â†’ C)

```
User Query
    â†“ DERIVES_FROM
[Raw Data Extraction] (Agent A)
    â†“ DERIVES_FROM
[Data Analysis] (Agent B)
    â†“ REQUIRES
[Validation Report] (Agent C)
```

**Come funziona**:
1. Agent A esegue, salva `raw_data` node
2. Agent B riceve query + `raw_data_id`, crea edge `analysis DERIVES_FROM raw_data`
3. Agent C riceve query + `analysis_id`, crea edge `validation REQUIRES analysis`
4. C puÃ² fare BFS per trovare anche `raw_data` (transitivitÃ )

**Vantaggio**: Non serve passare tutto il contesto a C, basta l'ID dell'analysis

### Pattern 2: Parallel Aggregation
**Scenario**: Multipli agent analizzano lo stesso input, un reporter aggrega

```
              [User Query]
                   â†“ SHARES_CONTEXT
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“          â†“          â†“
   [Financial] [Risk]    [Market]
   (Agent A)   (Agent B) (Agent C)
        â”‚          â”‚          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“ REQUIRES (all 3)
            [Final Report]
            (Agent D)
```

**Come funziona**:
1. A, B, C eseguono in parallelo, ognuno salva un nodo
2. Tutti creano edge `SHARES_CONTEXT` con lo stesso `user_query_id`
3. D riceve IDs di A, B, C, crea edges `report REQUIRES financial/risk/market`
4. D puÃ² query `SHARES_CONTEXT` per trovare tutto ciÃ² che Ã¨ stato prodotto per la stessa query

**Vantaggio**: Aggregazione flessibile senza conoscere a priori quanti agent partecipano

### Pattern 3: Iterative Refinement
**Scenario**: Agent raffina progressivamente un risultato

```
[Initial Analysis v1]
         â†“ INVALIDATES
[Refined Analysis v2]
         â†“ INVALIDATES
[Final Analysis v3]
```

**Come funziona**:
1. Agent produce `v1`, utente dÃ  feedback
2. Agent produce `v2`, crea edge `v2 INVALIDATES v1`
3. Quando altro agent cerca "latest analysis", filtra per nodi non invalidati

**Vantaggio**: Versioning automatico + audit trail

### Pattern 4: Cross-Validation
**Scenario**: Validator controlla consistency tra agent

```
[Analysis A]     [Analysis B]
     â”‚                 â”‚
     â””â”€â”€â”€â”€â”€CONTRADICTSâ”€â”˜ (detected by Validator)
              â†“
     [Conflict Resolution]
```

**Come funziona**:
1. Validator confronta output di A e B
2. Se trova inconsistenza, crea edge `A CONTRADICTS B`
3. Produce memoria `conflict_resolution` con edges `REQUIRES [A, B]`

**Vantaggio**: Conflict detection esplicito

---

## ğŸ¨ Design Decisions & Trade-offs

### Decision 1: Grafi Immutabili vs Mutabili
**Opzione A (Immutable)**: I nodi non si modificano mai, solo si aggiungono (con INVALIDATES)
- âœ… Pro: Audit trail completo, time-travel possibile
- âŒ Contro: Crescita continua del grafo (serve garbage collection)

**Opzione B (Mutable)**: I nodi si aggiornano in-place
- âœ… Pro: Efficienza memoria
- âŒ Contro: Perdita di storico

**Proposta**: **Immutable con GC policy**
- Regola: Mantieni solo ultimi N nodi per agent, oppure nodi degli ultimi M giorni
- Soft delete: Marca come "archived" invece di eliminare (per compliance)

### Decision 2: Relationship Transitivity
**Domanda**: Se `A REQUIRES B` e `B REQUIRES C`, allora `A REQUIRES C`?

**Approccio Parlant**: SÃ¬, BFS trova tutte le relazioni transitive

**Trade-off**:
- âœ… Pro: Context building automatico (trova tutte le dipendenze)
- âŒ Contro: Performance (BFS puÃ² essere costoso su grafi grandi)
- âš ï¸ AmbiguitÃ  semantica: Non tutte le relazioni sono transitive (CONTRADICTS non lo Ã¨!)

**Proposta**: **TransitivitÃ  configurabile per tipo di relazione**
```python
TRANSITIVE_RELATIONSHIPS = {
    DERIVES_FROM,    # SÃ¬, transitiva
    REQUIRES,        # SÃ¬, transitiva
    SHARES_CONTEXT,  # No, non transitiva (troppo vaga)
    CONTRADICTS      # No, non transitiva
}
```

### Decision 3: Embedding & Semantic Search
**Domanda**: Tutti i nodi devono avere embeddings per semantic search?

**Trade-off**:
- âœ… Pro: Powerful retrieval ("trova memorie simili a X")
- âŒ Contro: Costo computazionale (chiamata a embedding model), storage, latency

**Proposta**: **Opt-in per tipo di memoria**
```python
EMBED_TYPES = {
    AGENT_OUTPUT,    # SÃ¬, utile per "trova analisi simili"
    USER_INPUT,      # SÃ¬, utile per "query simili"
    TOOL_RESULT      # No, troppo strutturato (usa filtri esatti)
}
```

### Decision 4: Scope della Memoria
**Domanda**: Il grafo Ã¨ globale o per-session?

**Opzioni**:
- **Globale**: Tutte le memorie di tutti gli agent in un unico grafo
  - âœ… Cross-session learning possibile
  - âŒ Privacy concerns, complessitÃ  query

- **Per-Session**: Ogni sessione ha il suo grafo
  - âœ… Isolamento, privacy
  - âŒ No knowledge reuse

- **Ibrido**: Grafo per-session + knowledge base globale (read-only)
  - âœ… Best of both worlds
  - âŒ ComplessitÃ  architetturale

**Proposta**: **Per-Session con optional Knowledge Base**
```python
class MemoryGraph:
    session_graph: nx.DiGraph  # Read-write
    knowledge_base: nx.DiGraph  # Read-only (pre-popolato con "common knowledge")
```

### Decision 5: Persistence Strategy
**Domanda**: Dove/come persistere il grafo?

**Opzioni**:
1. **In-Memory (InMemoryStore)**: Dizionario Python + NetworkX
   - âœ… SemplicitÃ , velocitÃ 
   - âŒ Volatile, no scalability

2. **SQL (SQLiteStore / PostgreSQL)**: Tabelle `nodes`, `edges`
   - âœ… ACID, query relazionali
   - âŒ Graph traversal inefficiente (JOIN ricorsivi)

3. **Graph DB (Neo4j / ArangoDB)**: Native graph storage
   - âœ… Performance BFS, Cypher/AQL query
   - âŒ ComplessitÃ  deployment, dependency

4. **Vector DB (Chroma / Qdrant)**: Solo per semantic search
   - âœ… Embedding-based retrieval
   - âŒ No relationships native (servono ancora SQL/Graph DB per edges)

**Proposta**: **Layered Approach**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application (MemoryGraph API)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Document Store (nodes metadata)        â”‚  â† SQLite/PostgreSQL
â”‚  Edge Store (relationships)             â”‚  â† SQLite/PostgreSQL
â”‚  Vector Store (embeddings)              â”‚  â† Chroma/Qdrant (optional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Development**: InMemoryStore (no deps)
- **Production**: PostgreSQL + Chroma (scalability + semantic search)

---

## ğŸ”® Possibili Evoluzioni

### Evolution 1: Automatic Relationship Inference
**Idea**: L'orchestrator inferisce relazioni automaticamente invece che richiederle esplicitamente

**Esempio**:
```python
# Invece di:
validator.create_relationship(validation_id, analysis_id, REQUIRES)

# L'orchestrator fa:
orchestrator.register_agent(ValidatorAgent(), auto_infer_relations=True)
# â†’ Se Validator legge Analysis, crea REQUIRES automaticamente
```

**Implementazione**: Hook su `get_memory()` che traccia "chi legge cosa"

### Evolution 2: Semantic Relationship Types
**Idea**: Invece di relazioni hard-coded, permettere relazioni custom semantiche

**Esempio**:
```python
create_relationship(
    source_id,
    target_id,
    kind=CustomRelation(
        name="critiques",
        description="Source provides critical analysis of target",
        transitive=False
    )
)
```

**Uso**: Domain-specific relationships (medical: DIAGNOSES, legal: CITES)

### Evolution 3: Memory Compression
**Idea**: Automaticamente "comprimere" catene lunghe di memorie in summaries

**Esempio**:
```
[A] â†’ [B] â†’ [C] â†’ [D] â†’ [E]
         â†“ COMPRESS
[Summary(Aâ†’E)] + tombstones
```

**Trigger**: Quando catena supera threshold (e.g., 10 nodi), LLM genera summary

### Evolution 4: Conflict Resolution Agent
**Idea**: Agent specializzato che monitora il grafo per CONTRADICTS edges

**Flusso**:
1. Validator crea edge `[Analysis A] CONTRADICTS [Analysis B]`
2. ConflictResolver agent viene triggerato automaticamente
3. Analizza A e B, produce `[Resolution]` con `RESOLVES [A, B]`

### Evolution 5: Distributed Memory Graph
**Idea**: Ogni agent ha il proprio sotto-grafo, sincronizzati via gossip protocol

**Scenario**: Multi-datacenter deployment, ogni DC ha replica del grafo

**Sfide**: Consistency (eventual vs strong), conflict resolution, partitioning

---

## ğŸ“Š Metriche di Successo

Come sappiamo se il sistema funziona bene?

### Metriche Quantitative
1. **Context Efficiency**: Riduzione % di token passati tra agent
   - Before: Ogni sub-agent riceve full context (N tokens)
   - After: Ogni sub-agent riceve solo relevant IDs + BFS retrieval (M tokens)
   - Target: M < 0.5 * N

2. **Retrieval Precision**: % di memorie retrieved che sono effettivamente usate
   - Misura: Tracking di quali nodi l'agent include nella risposta finale
   - Target: > 80% delle memorie retrieved sono rilevanti

3. **Graph Density**: Numero di edges / numero di nodes
   - Troppo sparse: Poche relazioni (forse under-utilized)
   - Troppo dense: Troppe relazioni (forse over-connected, noise)
   - Target: 1.5-3 edges per node (empirico)

### Metriche Qualitative
1. **TracciabilitÃ **: Posso ricostruire "perchÃ© agent X ha detto Y"?
   - Test: Audit trail deve mostrare path da output a input originale

2. **Consistenza**: Gli agent producono output consistenti quando condividono memoria?
   - Test: Validator dovrebbe trovare meno CONTRADICTS quando usa memoria vs quando no

3. **ReusabilitÃ **: Posso riusare memorie in sessioni diverse?
   - Test: Knowledge base globale migliora accuracy su nuove query?

---

## ğŸ¤” Domande Aperte

### Q1: Privacy & Security
**Domanda**: Come gestiamo memorie sensibili nel grafo?

**Opzioni**:
- **Encryption**: Criptare `content` dei nodi sensibili
- **Access Control**: Permessi per-agent (agent A puÃ² leggere nodi di agent B?)
- **Ephemeral Memory**: Auto-delete dopo N minuti per dati PII

**Da decidere**: Policy di retention, compliance (GDPR, HIPAA)

### Q2: Multi-Tenancy
**Domanda**: In un deployment multi-utente, i grafi sono separati per user?

**Opzioni**:
- **Isolamento totale**: Ogni user ha il proprio grafo (privacy)
- **Shared Knowledge Base**: Grafo globale con memorie "pubbliche" (efficienza)

**Da decidere**: Architettura di deployment

### Q3: Real-Time Updates
**Domanda**: Se un nodo viene invalidato, gli agent che lo stanno usando devono essere notificati?

**Scenario**:
- Agent A sta usando memoria M
- Agent B invalida M (crea M' INVALIDATES M)
- A deve saperlo?

**Opzioni**:
- **Polling**: A controlla periodicamente se le sue memorie sono ancora valide
- **Push**: Event system notifica A quando M viene invalidata

### Q4: Testing & Simulation
**Domanda**: Come testiamo che il grafo si comporta come vogliamo?

**Approcci**:
- **Unit Tests**: Test per ogni tipo di relazione (DERIVES_FROM, REQUIRES, ecc.)
- **Integration Tests**: Workflow completi (3+ agent) con asserzioni sul grafo risultante
- **Simulation**: Generare grafi sintetici e validare proprietÃ  (no cycles, max depth, ecc.)

---

## ğŸ“š Riferimenti & Ispirazione

### Da Parlant
- **Relationships**: ENTAILMENT, PRIORITY, DEPENDENCY
  - Uso: Filtrare/ordinare guidelines matched
  - Trasposizione: Applicabile a memorie (quali memorie sono rilevanti?)

- **Journey Graphs**: Nodi + Archi per workflow multi-step
  - Uso: Navigare conversazioni strutturate
  - Trasposizione: Memorie come "journey" attraverso il workflow

- **BFS per TransitivitÃ **: Trovare relazioni indirette
  - Uso: Se A implica B e B implica C â†’ A implica C
  - Trasposizione: Context building automatico

### Da Altri Sistemi
- **Knowledge Graphs (Wikidata, DBpedia)**: EntitÃ  + relazioni semantiche
  - Lezione: Ontologie ben definite (relationship types) sono cruciali

- **Git DAG**: Commits + parent relationships
  - Lezione: ImmutabilitÃ  + branching/merging (potrebbe servire per conflitti?)

- **Blockchain**: Append-only log con hash-linking
  - Lezione: Tamper-proof audit trail (overkill per noi, ma ispirazione)

---

## ğŸ› ï¸ Roadmap Implementazione (Draft)

### Fase 1: MVP (Minimum Viable Product)
**Goal**: Dimostrare valore core con minimal implementation

**Scope**:
- âœ… `MemoryNode` (dataclass)
- âœ… `MemoryEdge` (dataclass)
- âœ… `MemoryGraph` (NetworkX + BFS)
- âœ… `InMemoryStore` (dizionario)
- âœ… 3 relationship types: DERIVES_FROM, REQUIRES, SHARES_CONTEXT
- âœ… `MemoryMixin` per BaseAgent
- âœ… Hook automatico per salvare tool results
- âœ… Esempio: Linear pipeline (A â†’ B â†’ C)

**Non-Goals** (rinviati):
- Persistence (solo RAM)
- Semantic search (solo relational queries)
- Conflict detection

### Fase 2: Production-Ready
**Goal**: Scalare a deployment reale

**Scope**:
- ğŸ“¦ Persistence: SQLite store (nodes + edges tables)
- ğŸ” Query optimization: Indexing, caching
- ğŸ§¹ Garbage collection: Auto-delete old memories
- ğŸ“Š Monitoring: Metriche (graph density, retrieval precision)
- ğŸ§ª Test suite: Unit + integration tests

### Fase 3: Advanced Features
**Goal**: FunzionalitÃ  avanzate per casi d'uso complessi

**Scope**:
- ğŸ§  Semantic search: Embeddings + Chroma
- ğŸ”— Automatic relationship inference
- ğŸ¤– Conflict resolution agent
- ğŸŒ Knowledge base globale (read-only)
- ğŸ“ˆ Visualization dashboard (NetworkX + Plotly)

---

## ğŸ’­ Conclusioni

Il sistema di memoria basato su grafi trasforma la coordinazione tra sub-agent da **orchestrazione esplicita** (l'orchestrator passa tutto il contesto) a **discovery implicita** (ogni agent trova ciÃ² che serve via relazioni semantiche).

**Key Insight**: Le relazioni tra memorie sono **altrettanto importanti** delle memorie stesse. Codificando esplicitamente "perchÃ©" due memorie sono connesse, rendiamo il sistema:
- **PiÃ¹ tracciabile** (audit trail)
- **PiÃ¹ efficiente** (context retrieval selettivo)
- **PiÃ¹ flessibile** (nuovi agent possono navigare il grafo esistente)

**Next Steps**:
1. Validare i concetti con prototyping rapido
2. Definire ontologia completa delle relationships (quali servono davvero?)
3. Implementare MVP e testare su workflow reali
4. Iterare in base a feedback

---

**Domande per Discussion**:
- Quali relationship types sono davvero essenziali vs nice-to-have?
- Per quali use case la memoria grafo Ã¨ overkill vs necessaria?
- Come bilanciare automatizzazione (auto-infer relations) vs controllo esplicito?
